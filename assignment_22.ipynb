{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ef783f",
   "metadata": {},
   "source": [
    "## Assignment No-2\n",
    "\n",
    "**Name** - Vishal Pattar  \n",
    "**Roll No** - 43556  \n",
    "**Class** - BE AIML  \n",
    "**Batch** - Batch D  \n",
    "**Subject** - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a390b",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Perform bag-of-words approach (count occurrence, normalized count occurrence), TF-IDF on data. \n",
    "Create embeddings using Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9342c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vishal\n",
      "[nltk_data]     Pattar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad1f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tweets list\n",
    "tweets = [\n",
    "    \"I'm getting on Borderlands and I will murder you all!\",\n",
    "    \"Borderlands is such a fun game! I love it!\",\n",
    "    \"Murder is bad, but this game is good ðŸ˜„\",\n",
    "    \"Iâ€™m logging off now, see you all tomorrow!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Tweets:\n",
      " [['i', \"'m\", 'getting', 'on', 'borderlands', 'and', 'i', 'will', 'murder', 'you', 'all', '!'], ['borderlands', 'is', 'such', 'a', 'fun', 'game', '!', 'i', 'love', 'it', '!'], ['murder', 'is', 'bad', ',', 'but', 'this', 'game', 'is', 'good', 'ðŸ˜„'], ['i', 'â€™', 'm', 'logging', 'off', 'now', ',', 'see', 'you', 'all', 'tomorrow', '!']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Lowercase and tokenize\n",
    "tokenized_tweets = [word_tokenize(tweet.lower()) for tweet in tweets]\n",
    "print(\"Tokenized Tweets:\\n\", tokenized_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b5276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      " ['all' 'and' 'bad' 'borderlands' 'but' 'fun' 'game' 'getting' 'good' 'is'\n",
      " 'it' 'logging' 'love' 'murder' 'now' 'off' 'on' 'see' 'such' 'this'\n",
      " 'tomorrow' 'will' 'you']\n",
      "\n",
      "Count Matrix:\n",
      " [[1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1]\n",
      " [0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 1 0 1 0 1 2 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1]]\n",
      "\n",
      "Normalized Term Frequency Matrix:\n",
      "         all    and    bad  borderlands    but       fun      game  getting  \\\n",
      "0  0.125000  0.125  0.000     0.125000  0.000  0.000000  0.000000    0.125   \n",
      "1  0.000000  0.000  0.000     0.142857  0.000  0.142857  0.142857    0.000   \n",
      "2  0.000000  0.000  0.125     0.000000  0.125  0.000000  0.125000    0.000   \n",
      "3  0.142857  0.000  0.000     0.000000  0.000  0.000000  0.000000    0.000   \n",
      "\n",
      "    good        is  ...  murder       now       off     on       see  \\\n",
      "0  0.000  0.000000  ...   0.125  0.000000  0.000000  0.125  0.000000   \n",
      "1  0.000  0.142857  ...   0.000  0.000000  0.000000  0.000  0.000000   \n",
      "2  0.125  0.250000  ...   0.125  0.000000  0.000000  0.000  0.000000   \n",
      "3  0.000  0.000000  ...   0.000  0.142857  0.142857  0.000  0.142857   \n",
      "\n",
      "       such   this  tomorrow   will       you  \n",
      "0  0.000000  0.000  0.000000  0.125  0.125000  \n",
      "1  0.142857  0.000  0.000000  0.000  0.000000  \n",
      "2  0.000000  0.125  0.000000  0.000  0.000000  \n",
      "3  0.000000  0.000  0.142857  0.000  0.142857  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Raw count\n",
    "vectorizer = CountVectorizer()\n",
    "bow_counts = vectorizer.fit_transform(tweets)\n",
    "print(\"Vocabulary:\\n\", vectorizer.get_feature_names_out())\n",
    "print(\"\\nCount Matrix:\\n\", bow_counts.toarray())\n",
    "\n",
    "# Normalized count (Term Frequency)\n",
    "import pandas as pd\n",
    "tf_matrix = bow_counts.toarray() / bow_counts.toarray().sum(axis=1, keepdims=True)\n",
    "tf_df = pd.DataFrame(tf_matrix, columns=vectorizer.get_feature_names_out())\n",
    "print(\"\\nNormalized Term Frequency Matrix:\\n\", tf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78cf532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vocabulary:\n",
      " ['all' 'and' 'bad' 'borderlands' 'but' 'fun' 'game' 'getting' 'good' 'is'\n",
      " 'it' 'logging' 'love' 'murder' 'now' 'off' 'on' 'see' 'such' 'this'\n",
      " 'tomorrow' 'will' 'you']\n",
      "\n",
      "TF-IDF Matrix:\n",
      " [[0.30956515 0.39264414 0.         0.30956515 0.         0.\n",
      "  0.         0.39264414 0.         0.         0.         0.\n",
      "  0.         0.30956515 0.         0.         0.39264414 0.\n",
      "  0.         0.         0.         0.39264414 0.30956515]\n",
      " [0.         0.         0.         0.32555709 0.         0.41292788\n",
      "  0.32555709 0.         0.         0.32555709 0.41292788 0.\n",
      "  0.41292788 0.         0.         0.         0.         0.\n",
      "  0.41292788 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.35968533 0.         0.35968533 0.\n",
      "  0.28358005 0.         0.35968533 0.56716009 0.         0.\n",
      "  0.         0.28358005 0.         0.         0.         0.\n",
      "  0.         0.35968533 0.         0.         0.        ]\n",
      " [0.31553666 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40021825\n",
      "  0.         0.         0.40021825 0.40021825 0.         0.40021825\n",
      "  0.         0.         0.40021825 0.         0.31553666]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tweets)\n",
    "print(\"TF-IDF Vocabulary:\\n\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977467a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec embedding for 'game':\n",
      " [-0.01427302  0.00248307 -0.0143419  -0.00448909  0.00743625  0.01166134\n",
      "  0.00240047  0.00420798 -0.00822306  0.01444267 -0.01261127  0.00929099\n",
      " -0.01643045  0.00406776 -0.00995342 -0.0084942  -0.00621273  0.01130777\n",
      "  0.01159351 -0.00995915  0.00154445 -0.01698569  0.01562924  0.01850968\n",
      " -0.00549363  0.00160748  0.00149222  0.01095682 -0.01721063  0.00117423\n",
      "  0.01373279  0.00446473  0.00225383 -0.01864095  0.01696353 -0.01252604\n",
      " -0.00598735  0.00698181 -0.00155383  0.00282455  0.00357028 -0.01365527\n",
      " -0.01944894  0.01808634  0.01240194 -0.01383419  0.00680082  0.00040813\n",
      "  0.00950675 -0.01423853]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_tweets, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Check embedding for a word\n",
    "word = \"game\"\n",
    "if word in w2v_model.wv:\n",
    "    print(f\"Word2Vec embedding for '{word}':\\n\", w2v_model.wv[word])\n",
    "else:\n",
    "    print(f\"'{word}' not in vocabulary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
