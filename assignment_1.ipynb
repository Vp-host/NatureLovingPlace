{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ef783f",
   "metadata": {},
   "source": [
    "## Assignment No-1\n",
    "**Name** - Vishal Pattar  \n",
    "**Roll No** - 43556  \n",
    "**Class** - BE AIML  \n",
    "**Batch** - Batch D  \n",
    "**Subject** - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a390b",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Perform tokenization (Whitespace, Punctuation-based, Treebank, Tweet, MWE) using NLTK library. \n",
    "Use porter stemmer and snowball stemmer for stemming. Use any technique for lemmatization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f181b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vishal\n",
      "[nltk_data]     Pattar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Vishal\n",
      "[nltk_data]     Pattar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Vishal\n",
      "[nltk_data]     Pattar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer, TweetTokenizer, RegexpTokenizer, MWETokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e9e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " I'm getting on Borderlands, and I will murder you all! ðŸ˜ˆ #gaming #fun @user\n"
     ]
    }
   ],
   "source": [
    "# Sample tweet text\n",
    "text = \"I'm getting on Borderlands, and I will murder you all! ðŸ˜ˆ #gaming #fun @user\"\n",
    "print(\"Original Text:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211aa292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace Tokenization:\n",
      " [\"I'm\", 'getting', 'on', 'Borderlands,', 'and', 'I', 'will', 'murder', 'you', 'all!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Split by whitespace\n",
    "whitespace_tokens = text.split()\n",
    "print(\"Whitespace Tokenization:\\n\", whitespace_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf52d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation-Based Tokenization:\n",
      " ['I', 'm', 'getting', 'on', 'Borderlands', 'and', 'I', 'will', 'murder', 'you', 'all', 'gaming', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Regex tokenizer (splits on non-word characters)\n",
    "regex_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "regex_tokens = regex_tokenizer.tokenize(text)\n",
    "print(\"Punctuation-Based Tokenization:\\n\", regex_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc765f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank Tokenization:\n",
      " ['I', \"'m\", 'getting', 'on', 'Borderlands', ',', 'and', 'I', 'will', 'murder', 'you', 'all', '!', 'ðŸ˜ˆ', '#', 'gaming', '#', 'fun', '@', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Treebank Tokenizer (standard for grammatical text)\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "treebank_tokens = treebank_tokenizer.tokenize(text)\n",
    "print(\"Treebank Tokenization:\\n\", treebank_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b4bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet Tokenization:\n",
      " [\"I'm\", 'getting', 'on', 'Borderlands', ',', 'and', 'I', 'will', 'murder', 'you', 'all', '!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Tweet Tokenizer (handles emojis, mentions, hashtags better)\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokens = tweet_tokenizer.tokenize(text)\n",
    "print(\"Tweet Tokenization:\\n\", tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b986bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Word Expression Tokenization:\n",
      " [\"I'm\", 'getting_on', 'Borderlands,', 'and', 'I', 'will', 'murder', 'you', 'all!', 'ðŸ˜ˆ', '#gaming', '#fun', '@user']\n"
     ]
    }
   ],
   "source": [
    "# Define some multi-word expressions\n",
    "mwe_tokenizer = MWETokenizer([('getting', 'on'), ('Borderlands', ',')])\n",
    "mwe_tokens = mwe_tokenizer.tokenize(text.split())\n",
    "print(\"Multi-Word Expression Tokenization:\\n\", mwe_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812248a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer:\n",
      " ['i', 'm', 'get', 'on', 'borderland', 'and', 'i', 'will', 'murder', 'you', 'all', 'game', 'fun', 'user']\n",
      "Snowball Stemmer:\n",
      " ['i', 'm', 'get', 'on', 'borderland', 'and', 'i', 'will', 'murder', 'you', 'all', 'game', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "tokens = regex_tokens  # using regex-based clean tokens\n",
    "\n",
    "porter_stems = [porter.stem(token) for token in tokens]\n",
    "snowball_stems = [snowball.stem(token) for token in tokens]\n",
    "\n",
    "print(\"Porter Stemmer:\\n\", porter_stems)\n",
    "print(\"Snowball Stemmer:\\n\", snowball_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee65250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Tokens:\n",
      " ['I', 'm', 'getting', 'on', 'Borderlands', 'and', 'I', 'will', 'murder', 'you', 'all', 'gaming', 'fun', 'user']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatization (default is noun unless specified)\n",
    "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(\"Lemmatized Tokens:\\n\", lemmas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
